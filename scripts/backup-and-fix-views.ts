import pg from 'pg'
import { config } from 'dotenv'
import fs from 'fs'

config()

const { Pool } = pg

async function backupAndFixViews() {
  const pool = new Pool({
    host: process.env.AWS_DB_HOST,
    port: parseInt(process.env.AWS_DB_PORT || '5432'),
    database: process.env.AWS_DB_NAME,
    user: process.env.AWS_DB_USER,
    password: process.env.AWS_DB_PASSWORD,
    ssl: {
      rejectUnauthorized: false,
    },
  })

  try {
    console.log('\nğŸ” VIEW ë°±ì—… ë° TIMESTAMP ì¹¼ëŸ¼ ë³€í™˜\n')
    console.log('=' .repeat(60))

    // 1. VIEW ì •ì˜ ë°±ì—…
    console.log('\nğŸ“¦ Step 1: VIEW ì •ì˜ ë°±ì—… ì¤‘...\n')
    
    const views = [
      'user_effective_roles',
      'active_salary_contracts', 
      'salary_contract_history'
    ]

    const viewDefinitions = new Map<string, string>()

    for (const viewName of views) {
      const result = await pool.query(`
        SELECT pg_get_viewdef('${viewName}'::regclass, true) as definition
      `)
      
      const definition = result.rows[0].definition
      viewDefinitions.set(viewName, definition)
      
      console.log(`  âœ… ${viewName} ë°±ì—… ì™„ë£Œ`)
    }

    // ë°±ì—… íŒŒì¼ ì €ì¥
    const backupContent = Array.from(viewDefinitions.entries())
      .map(([name, def]) => `-- VIEW: ${name}\nCREATE OR REPLACE VIEW ${name} AS\n${def};\n`)
      .join('\n\n')
    
    fs.writeFileSync('migrations/backup_views.sql', backupContent)
    console.log('\n  ğŸ“„ ë°±ì—… íŒŒì¼ ì €ì¥: migrations/backup_views.sql')

    // 2. VIEW DROP
    console.log('\nğŸ—‘ï¸  Step 2: VIEW ì œê±° ì¤‘...\n')
    
    await pool.query('BEGIN')
    
    for (const viewName of views.reverse()) {
      await pool.query(`DROP VIEW IF EXISTS ${viewName} CASCADE`)
      console.log(`  âœ… ${viewName} ì œê±° ì™„ë£Œ`)
    }

    // 3. ì¹¼ëŸ¼ ë³€í™˜
    console.log('\nğŸ”§ Step 3: TIMESTAMP â†’ TIMESTAMPTZ ë³€í™˜ ì¤‘...\n')
    
    await pool.query(`
      ALTER TABLE employee_roles
      ALTER COLUMN expires_at TYPE TIMESTAMPTZ
      USING expires_at AT TIME ZONE 'Asia/Seoul'
    `)
    console.log('  âœ… employee_roles.expires_at ë³€í™˜ ì™„ë£Œ')

    await pool.query(`
      ALTER TABLE salary_contracts
      ALTER COLUMN created_at TYPE TIMESTAMPTZ
      USING created_at AT TIME ZONE 'Asia/Seoul',
      ALTER COLUMN updated_at TYPE TIMESTAMPTZ
      USING updated_at AT TIME ZONE 'Asia/Seoul'
    `)
    console.log('  âœ… salary_contracts.created_at ë³€í™˜ ì™„ë£Œ')
    console.log('  âœ… salary_contracts.updated_at ë³€í™˜ ì™„ë£Œ')

    // 4. VIEW ì¬ìƒì„±
    console.log('\nğŸ—ï¸  Step 4: VIEW ì¬ìƒì„± ì¤‘...\n')
    
    for (const [viewName, definition] of viewDefinitions) {
      await pool.query(`CREATE OR REPLACE VIEW ${viewName} AS ${definition}`)
      console.log(`  âœ… ${viewName} ì¬ìƒì„± ì™„ë£Œ`)
    }

    await pool.query('COMMIT')

    // 5. ê²€ì¦
    console.log('\nâœ… Step 5: ìµœì¢… ê²€ì¦ ì¤‘...\n')
    
    const verifyResult = await pool.query(`
      SELECT COUNT(*) as timestamp_count
      FROM information_schema.columns
      WHERE table_schema = 'public'
        AND table_name NOT LIKE 'pg_%'
        AND (
          column_name LIKE '%_date%' OR
          column_name LIKE '%_time%' OR
          column_name LIKE '%_at'
        )
        AND udt_name = 'timestamp'
    `)

    const remainingTimestamp = parseInt(verifyResult.rows[0].timestamp_count)

    console.log('=' .repeat(60))
    if (remainingTimestamp === 0) {
      console.log('ğŸ‰ ì™„ë²½! ëª¨ë“  TIMESTAMP ì¹¼ëŸ¼ì´ TIMESTAMPTZë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤!')
    } else {
      console.log(`âš ï¸  ì•„ì§ ${remainingTimestamp}ê°œì˜ TIMESTAMP ì¹¼ëŸ¼ì´ ë‚¨ì•„ìˆìŠµë‹ˆë‹¤.`)
    }
    console.log('=' .repeat(60))
    console.log()

  } catch (error) {
    console.error('\nâŒ ì˜¤ë¥˜ ë°œìƒ:', error)
    console.log('\nğŸ”„ ë¡¤ë°± ì¤‘...')
    await pool.query('ROLLBACK')
    console.log('âœ… ë¡¤ë°± ì™„ë£Œ - ë³€ê²½ì‚¬í•­ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.')
    console.log('\nğŸ’¡ ë°±ì—… íŒŒì¼ë¡œ ìˆ˜ë™ ë³µêµ¬ ê°€ëŠ¥: migrations/backup_views.sql')
    process.exit(1)
  } finally {
    await pool.end()
  }
}

backupAndFixViews()

